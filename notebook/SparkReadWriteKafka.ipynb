{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession,DataFrame\n",
    "import os\n",
    "import numpy as np\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.types import *\n",
    "import io\n",
    "import time\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "local=True\n",
    "# spark.rpc.message.maxSize if for write large csv file. The default value is 128, here we set it to 1024\n",
    "if local:\n",
    "    spark = SparkSession \\\n",
    "    .builder.master(\"local[4]\") \\\n",
    "    .appName(\"SparkArrowCompression\") \\\n",
    "    .config('spark.jars.packages', 'org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.1') \\\n",
    "    .getOrCreate()\n",
    "else: \n",
    "    spark = SparkSession \\\n",
    "    .builder.master(\"k8s://https://kubernetes.default.svc:443\") \\\n",
    "    .appName(\"SparkArrowCompression\") \\\n",
    "    .config(\"spark.kubernetes.container.image\", \"inseefrlab/jupyter-datascience:master\") \\\n",
    "    .config(\"spark.kubernetes.authenticate.driver.serviceAccountName\", os.environ['KUBERNETES_SERVICE_ACCOUNT']) \\\n",
    "    .config(\"spark.executor.instances\", \"4\") \\\n",
    "    .config(\"spark.executor.memory\",\"8g\") \\\n",
    "    .config(\"spark.kubernetes.namespace\", os.environ['KUBERNETES_NAMESPACE']) \\\n",
    "    .config('spark.jars.packages', 'org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.1') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1.1\n"
     ]
    }
   ],
   "source": [
    "print(spark.sparkContext.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0928 14:58:20.035335    2894 request.go:655] Throttling request took 1.171086553s, request: GET:https://kubernetes.default/apis/coordination.k8s.io/v1beta1?timeout=32s\n",
      "NAME                               READY   STATUS    RESTARTS   AGE\n",
      "flume-test-agent-df8c5b944-vtjbx   1/1     Running   0          9d\n",
      "jupyter-266220-5bf4b859f8-wfkz6    1/1     Running   0          7h24m\n",
      "kafka-client                       1/1     Running   0          82m\n",
      "kafka-client1                      1/1     Running   0          79m\n",
      "kafka-server-0                     1/1     Running   0          9d\n",
      "kafka-server-1                     1/1     Running   0          9d\n",
      "kafka-server-2                     1/1     Running   0          9d\n",
      "kafka-server-zookeeper-0           1/1     Running   0          9d\n",
      "rstudio-625080-8d7b9fbfb-wdmlw     1/1     Running   0          3h10m\n"
     ]
    }
   ],
   "source": [
    "! kubectl get pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0928 13:59:34.345375    1999 request.go:655] Throttling request took 1.166803404s, request: GET:https://kubernetes.default/apis/acme.cert-manager.io/v1alpha3?timeout=32s\n",
      "I0928 13:59:38.077155    2034 request.go:655] Throttling request took 1.181243355s, request: GET:https://kubernetes.default/apis/acme.cert-manager.io/v1beta1?timeout=32s\n",
      "pod \"sparkarrowcompression-77efdb7c26eb6e0b-exec-5\" deleted\n",
      "pod \"sparkarrowcompression-77efdb7c26eb6e0b-exec-6\" deleted\n",
      "pod \"sparkarrowcompression-77efdb7c26eb6e0b-exec-7\" deleted\n",
      "pod \"sparkarrowcompression-77efdb7c26eb6e0b-exec-8\" deleted\n"
     ]
    }
   ],
   "source": [
    "! kubectl get pods | grep sparkarrow | awk '{print $1}' | xargs kubectl delete pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(\"xiaomi\", \"2007\"),\n",
    "        (\"xiaomi 3G\",\"2008\"),\n",
    "      (\"xiaomi 3GS\",\"2009\"),\n",
    "      (\"xiaomi 4\",\"2010\"),\n",
    "      (\"xiaomi 4S\",\"2011\"),\n",
    "      (\"xiaomi 5\",\"2012\"),\n",
    "      (\"xiaomi 8\",\"2014\"),\n",
    "      (\"xiaomi 3GS\",\"2009\"),\n",
    "        (\"xiaomi 10\",\"2017\")\n",
    "       ]\n",
    "\n",
    "df = spark.createDataFrame(data).toDF(\"key\",\"value\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|       key|value|\n",
      "+----------+-----+\n",
      "|    xiaomi| 2007|\n",
      "| xiaomi 3G| 2008|\n",
      "|xiaomi 3GS| 2009|\n",
      "|  xiaomi 4| 2010|\n",
      "| xiaomi 4S| 2011|\n",
      "|  xiaomi 5| 2012|\n",
      "|  xiaomi 8| 2014|\n",
      "|xiaomi 3GS| 2009|\n",
      "| xiaomi 10| 2017|\n",
      "+----------+-----+\n",
      "\n",
      "root\n",
      " |-- key: string (nullable = true)\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\",\"kafka-server.user-pengfei.svc.cluster.local:9092\") \\\n",
    "  .option(\"topic\",\"test_topic\") \\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subscribe to 1 topic, with headers\n",
    "df = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"kafka-server.user-pengfei.svc.cluster.local:9092\") \\\n",
    "  .option(\"subscribe\", \"test_topic\") \\\n",
    "  .option(\"includeHeaders\", \"true\") \\\n",
    "  .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark \\\n",
    "  .read \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"kafka-server.user-pengfei.svc.cluster.local:9092\") \\\n",
    "  .option(\"subscribe\", \"test_topic\") \\\n",
    "  .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+---------+------+-----------------------+-------------+\n",
      "|key       |value|topic     |partition|offset|timestamp              |timestampType|\n",
      "+----------+-----+----------+---------+------+-----------------------+-------------+\n",
      "|iphone 3GS|2009 |test_topic|0        |0     |2021-09-28 14:38:06.326|0            |\n",
      "|iphone 8  |2014 |test_topic|0        |1     |2021-09-28 14:38:06.326|0            |\n",
      "|iphone 4  |2010 |test_topic|0        |2     |2021-09-28 14:38:06.356|0            |\n",
      "|iphone    |2007 |test_topic|0        |3     |2021-09-28 14:38:06.326|0            |\n",
      "|iphone 4S |2011 |test_topic|0        |4     |2021-09-28 14:38:06.326|0            |\n",
      "|iphone 10 |2017 |test_topic|0        |5     |2021-09-28 14:38:06.357|0            |\n",
      "|iphone 3G |2008 |test_topic|0        |6     |2021-09-28 14:38:06.357|0            |\n",
      "|iphone 5  |2012 |test_topic|0        |7     |2021-09-28 14:38:06.357|0            |\n",
      "|xiaomi    |2007 |test_topic|0        |8     |2021-09-28 15:18:02.01 |0            |\n",
      "|xiaomi 3GS|2009 |test_topic|0        |9     |2021-09-28 15:18:02.011|0            |\n",
      "|xiaomi 3G |2008 |test_topic|0        |10    |2021-09-28 15:18:02.024|0            |\n",
      "|xiaomi 4S |2011 |test_topic|0        |11    |2021-09-28 15:18:02.011|0            |\n",
      "|xiaomi 8  |2014 |test_topic|0        |12    |2021-09-28 15:18:02.011|0            |\n",
      "|xiaomi 4  |2010 |test_topic|0        |13    |2021-09-28 15:18:02.024|0            |\n",
      "|xiaomi 5  |2012 |test_topic|0        |14    |2021-09-28 15:18:02.024|0            |\n",
      "|xiaomi 3GS|2009 |test_topic|0        |15    |2021-09-28 15:18:02.024|0            |\n",
      "|xiaomi 10 |2017 |test_topic|0        |16    |2021-09-28 15:18:02.024|0            |\n",
      "+----------+-----+----------+---------+------+-----------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df.selectExpr(\"CAST(key AS STRING)\", \n",
    "             \"CAST(value AS STRING)\",\"topic\",\"partition\",\"offset\",\"timestamp\",\"timestampType\")\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
