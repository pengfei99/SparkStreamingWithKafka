{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.conf.SparkConf at 0x7f1bd9e2a690>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "import os\n",
    "\n",
    "conf = SparkConf()\n",
    "\n",
    "#url par défaut d'une api kubernetes accédé depuis l'intérieur du cluster (ici le notebook tourne lui même dans kubernetes)\n",
    "conf.setMaster(\"k8s://https://kubernetes.default.svc:443\")\n",
    "\n",
    "#image des executors spark: pour des raisons de simplicité on réutilise l'image du notebook\n",
    "conf.set(\"spark.kubernetes.container.image\", \"inseefrlab/jupyter-datascience:master\")\n",
    "\n",
    "# Nom du compte de service pour contacter l'api kubernetes : attention le package du datalab crée lui même cette variable d'enviromment.\n",
    "# Dans un pod du cluster kubernetes il faut lire le fichier /var/run/secrets/kubernetes.io/serviceaccount/token\n",
    "# Néanmoins ce paramètre est inutile car le contexte kubernetes local de ce notebook est préconfiguré\n",
    "# conf.set(\"spark.kubernetes.authenticate.driver.serviceAccountName\", os.environ['KUBERNETES_SERVICE_ACCOUNT']) \n",
    "\n",
    "# Nom du namespace kubernetes\n",
    "conf.set(\"spark.kubernetes.namespace\", os.environ['KUBERNETES_NAMESPACE'])\n",
    "\n",
    "# Nombre d'executeur spark, il se lancera autant de pods kubernetes que le nombre indiqué.\n",
    "conf.set(\"spark.executor.instances\", \"5\")\n",
    "\n",
    "# Mémoire alloué à la JVM\n",
    "# Attention par défaut le pod kubernetes aura une limite supérieur qui dépend d'autres paramètres.\n",
    "# On manipulera plus bas pour vérifier la limite de mémoire totale d'un executeur\n",
    "conf.set(\"spark.executor.memory\", \"4g\")\n",
    "\n",
    "conf.set(\"spark.kubernetes.driver.pod.name\", os.environ['KUBERNETES_POD_NAME'])\n",
    "\n",
    "# Paramètres d'enregistrement des logs spark d'application\n",
    "# Attention ce paramètres nécessitent la création d'un dossier spark-history. Spark ne le fait pas lui même pour des raisons obscurs\n",
    "# import s3fs\n",
    "# endpoint = \"https://\"+os.environ['AWS_S3_ENDPOINT']\n",
    "# fs = s3fs.S3FileSystem(client_kwargs={'endpoint_url': endpoint})\n",
    "# fs.touch('s3://tm8enk/spark-history/.keep')\n",
    "# sparkconf.set(\"spark.eventLog.enabled\",\"true\")\n",
    "# sparkconf.set(\"spark.eventLog.dir\",\"s3a://tm8enk/spark-history\")\n",
    "#ici pour gérer le dateTimeFormatter dépendant de la verion de java...\n",
    "conf.set(\"spark.sql.legacy.timeParserPolicy\",\"LEGACY\")\n",
    "#conf.set(\"spark.sql.session.timeZone\", \"UTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"streaming\").config(conf = conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
